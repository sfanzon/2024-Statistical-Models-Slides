---
title: "Statistical Models"
subtitle: "Lecture 8"
from: markdown+emoji
author: 
    - name: Dr. Silvio Fanzon
      id: sf
      email: S.Fanzon@hull.ac.uk
      url: https://www.silviofanzon.com
      affiliations: University of Hull
    - name: Dr. John Fry
      id: jf
      email: J.M.Fry@hull.ac.uk
      url: https://www.hull.ac.uk/staff-directory/john-fry
      affiliations: University of Hull
---



::: {.content-hidden}
$
{{< include macros.tex >}}
$
:::




# Lecture 8: <br>The maths of <br>regression {background-color="#cc0164" visibility="uncounted"}

::: footer

<div color="#cc0164">  </div>

:::





## Outline of Lecture 8

1. Simple linear regression
2. Multiple linear regression
3. Simple regression as a multiple regression
4. Two sample t-test as multiple regression








# Part 1: <br>Simple linear<br>regression {background-color="#cc0164" visibility="uncounted"}

::: footer

<div color="#cc0164">  </div>

:::





## Simple linear regression {.smaller}


-  Important conceptually to illustrate the method of least squares

- Shows where the A-level formulae come from


- The simple linear regression model is
$$
y_i = \alpha+  \beta x_i + \e_i
$$

- The random errors $\e_i$ are iid $N(0, \sigma^2)$

- This means that any observation errors are assumed to be independent of each other and have the same statistical description

- This model formulation also means that the observed $y_i$ are also normally distributed
$$
y_i \sim N(\alpha + \beta x_i, \sigma^2)
$$




# Part 2: <br>Multiple linear<br>regression {background-color="#cc0164" visibility="uncounted"}

::: footer

<div color="#cc0164">  </div>

:::






# Part 3: <br>Simple regression as<br> multiple regression {background-color="#cc0164" visibility="uncounted"}

::: footer

<div color="#cc0164">  </div>

:::




# Part 4: <br>Two sample t-test<br> as multiple regression {background-color="#cc0164" visibility="uncounted"}

::: footer

<div color="#cc0164">  </div>

:::