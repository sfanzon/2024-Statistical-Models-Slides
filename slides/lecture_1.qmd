---
title: "Statistical Models"
subtitle: "Lecture 1"
author: 
    - name: Dr. Silvio Fanzon
      id: sf
      email: S.Fanzon@hull.ac.uk
      url: https://www.silviofanzon.com
      affiliations: University of Hull
    - name: Dr. John Fry
      id: jf
      email: J.M.Fry@hull.ac.uk
      url: https://www.hull.ac.uk/staff-directory/john-fry
      affiliations: University of Hull
---


# Lecture 1: <br>An introduction to Statistics {background-color="#cc0164" visibility="uncounted"}




## Outline of Lecture 1

1. Module info
2. Motivation
3. Probability background
4. Statistics background





# Part 1: <br>Module info {background-color="#cc0164" visibility="uncounted"}


## Contact details

- **Lecturer:** Dr. Silvio Fanzon
- **Call me:**
  * Silvio
  * Dr. Fanzon
- **Email:** S.Fanzon@hull.ac.uk
- **Office:** Room 104a, Larkin Building
- **Office hours:** Wednesday 12:00-13:00
- **Meetings**: in my office or send me an Email






## References
### Main textbooks 


::: {.column width="61%"}

<br>

Slides are self-contained and based on the book

- [@bingham-fry] Bingham, N. H. and Fry, J. M. 
<br> *Regression: Linear models in statistics.* <br> Springer, 2010


:::


::: {.column width="38%"}

[![](images/bingham_fry.png){width=90%}](https://link.springer.com/book/10.1007/978-1-84882-969-5)

:::





## References
### Main textbooks 


::: {.column width="61%"}
<br>

.. and also on the book

- [@fry-burke] Fry, J. M. and Burke, M. 
<br>*Quantitative methods in finance using R.* 
<br>Open University Press, 2022

:::


::: {.column width="38%"}

[![](images/fry_burke.png){width=90%}](https://www.mheducation.co.uk/quantitative-methods-in-finance-using-r-9780335251261-emea-group)

:::







## References
### Secondary References 

::: {.column width="69%"}
- [@casella-berger] Casella, G. and Berger R. L. <br>
*Statistical inference.*
<br> Second Edition, Brooks/Cole, 2002


- [@degroot] DeGroot M. H. and Schervish M. J. <br> 
*Probability and Statistics.* 
<br> Fourth Edition, Addison-Wesley, 2012


- [@dalgaard] Dalgaard, P. 
<br> *Introductory statistics with R.*
<br> Second Edition, Springer, 2008   

:::


::: {.column width="30%"}

**Probability & Statistics manual**



**Easier Probability & Statistics manual**



**R manual**
:::






## The nature of Statistics
### Statistics is a mathematical subject

- Maths skills will give you a head start

- There are other occasions where common sense and *detective skills* can be more important

- Provides an early example of mathematics working in concert with the available computation




## The nature of Statistics
### We will use a combination of hand calculation and software

- Recognises that you are maths students
- Software (R) is really useful, particularly for dissertations
- Please bring your laptop into class
- Download R onto your laptop







## Overview of the module


Module has **11 Lectures**, divided into two parts:

- **Part I** - Mathematical statistics

- **Part II** - Applied statistics





## Overview of the module
### Part I - Mathematical statistics

1. Introduction to statistics
2. Normal distribution family and one-sample hypothesis tests
3. Two-sample hypothesis tests
4. The chi-squared test
5. Non-parametric statistics
6. The maths of regression





## Overview of the module
### Part II - Applied statistics


7. An introduction to practical regression
8. The extra sum of squares principle and regression modelling assumptions
9. Violations of regression assumptions -- Autocorrelation
10. Violation of regression assumptions -- Multicollinearity
10. Dummy variable regression models 





# Part 2: <br>Motivation {background-color="#cc0164" visibility="uncounted"}



## Simple but useful questions {.smaller}


::: {.column width="48%"}

**Generic data:**

- What is a *typical* observation
  * What is the **mean**?

- How spread out is the data?
  * What is the **variance**?

:::


::: {.column width="48%"}

**Regression:**

- What happens to $Y$ as $X$ increases?
  * increases?
  * decreases?
  * nothing?

:::



**Statistics answers these questions systematically**

- important for large datasets
- The same mathematical machinery (normal family of distributions) can be applied to both questions




## Analysing a general dataset

**Two basic questions:**

1. Location or mean
2. Spread or variance


**Statistics enables to answer systematically:**

1. One sample and two-sample $t$-test
2. Chi-squared test and $F$-test





## Recall the following sketch

![Curve represents data distribution](images/Fig1.png){width=90%}




## Motivating regression

**Basic question in regression:**

- What happens to $Y$ as $X$ increases?

  * increases?
  * decreases?
  * nothing?


**In this way regression can be seen as a more advanced version of high-school maths**







## Positive gradient

As $X$ increases $Y$ increases

```{r}
#| echo: false
#| fig-asp: 1


# Create a scatter plot with no data points (type = "n")
plot(
  1, 1, 
  type = "n", 
  xlab = "", 
  ylab = "", 
  xlim = c(0, 5), 
  ylim = c(0, 5), 
  frame.plot = TRUE, 
  axes = FALSE, 
  asp = 1)


mtext("X", side=1, line=3, cex=3)
mtext("Y", side=2, line=2, cex=3)

# Add the line y = x
abline(
  a = 0, 
  b = 1, 
  col = "black", 
  lwd = 2)

```




## Negative gradient

As $X$ increases $Y$ decreases

```{r}
#| echo: false
#| fig-asp: 1


# Create a scatter plot with no data points (type = "n")
plot(
  1, 1, 
  type = "n", 
  xlab = "", 
  ylab = "", 
  xlim = c(-3, 3), 
  ylim = c(-3, 3), 
  frame.plot = TRUE, 
  axes = FALSE, 
  asp = 1)



mtext("X", side=1, line=3, cex=3)
mtext("Y", side=2, line=2, cex=3)

# Add the line y = x
abline(
  a = 0, 
  b = -1, 
  col = "black", 
  lwd = 2)

```





## Zero gradient

Changes in $X$ do not affect $Y$

```{r}
#| echo: false
#| fig-asp: 1


# Create a scatter plot with no data points (type = "n")
plot(
  1, 1, 
  type = "n", 
  xlab = "", 
  ylab = "", 
  xlim = c(0, 5), 
  ylim = c(0, 5), 
  frame.plot = TRUE, 
  axes = FALSE, 
  asp = 1)


mtext("X", side=1, line=3, cex=3)
mtext("Y", side=2, line=2, cex=3)

# Add the line y = x
abline(
  a = 2.5, 
  b = 0, 
  col = "black", 
  lwd = 2)

```





## Real data example


- Real data is more **imperfect**
- But the same basic idea applies
- Example: 
    * $X =$ Stock price
    * $Y =$ Gold price








## Real data example
### How does real data look like?

::: {style="font-size: 0.75em"}
Dataset with $33$ entries for Stock and Gold price pairs
:::


::: {style="font-size: 0.55em"}
```{r}
#| echo: false
#| layout-ncol: 1

data <- read.table("datasets/L3eg1data.txt")

#Add column labels to data
colnames(data) <- c("Stock Price","Gold Price")

# Output markdown table from data
knitr::kable(
  list(data[1:11,], data[12:22,], data[23:33,]),
  row.names = TRUE,
  format = "html", 
  table.attr = 'class="table simple table-striped table-hover"',
) 


```


:::




## Real data example {.smaller}
### Visualizing the data


::::: {.columns style='display: flex !important; height: 80%;'}

::: {.column width="38%" style='display: flex; justify-content: center; align-items: center;'}

- Plot Stock Price against Gold Price

- Observation: 

  * As Stock price decreases, Gold price increases

- Why? This might be because:
    * Stock price decreases
    * People invest in secure assets (Gold)
    * Gold demand increases
    * Gold price increases

:::


::: {.column width="61%" style='display: flex; justify-content: center; align-items: center;'}

```{r}
#| echo: false
#| fig-asp: 1

data1 <- read.table("datasets/L3eg1data.txt")
realgoldprice<-data1[,1]
realstockprice<-data1[,2]
plot(realstockprice, 
  realgoldprice, 
  xlab="", 
  ylab="")

mtext("Stock Price", side=1, line=3, cex=2)
mtext("Gold Price", side=2, line=2.5, cex=2)

```

:::

:::::




## Don't panic {.smaller}

- Regression problems can look a lot harder than they really are
  * Basic question remains the same: what happens to $Y$ as $X$ increases?

- Beware of jargon. Various authors distinguish between
  * Two variable regression model
  * Multiple regression model
  * Analysis of Variance
  * Analysis of Covariance

- Despite these apparent differences:
  * Mathematical methodology stays (essentially) the same
  * regression-fitting commands in R stay (essentially) the same





# Part 3: <br>Probability background {background-color="#cc0164" visibility="uncounted"}



## Boh

We start with a recap of things seen in the Introduction to Prob module



# Part 4: <br>Statistics background {background-color="#cc0164" visibility="uncounted"}



# Thank you! {background-color="#cc0164" visibility="uncounted"}


## References







::: {.content-hidden}


## Real data example
### How does real data look like?

::: {style="font-size: 0.8em"}
Dataset with $33$ entries for Stock and Gold price pairs
:::

::: {style="font-size: 0.6em"}

```{r}
#| echo: false
#| layout-ncol: 3
#| tbl-cap: "Dataset with 33 entries for Stock and Gold price pairs"

# Read dataset
data <- read.table("datasets/L3eg1data.txt")

#Add column labels to data
colnames(data) <- c("Stock Price","Gold Price")

# Output markdown table from data

knitr::kable(data[1:11,], row.names = TRUE)

knitr::kable(data[12:22,], row.names = TRUE)

knitr::kable(data[23:33,], row.names = TRUE)

```

:::

:::

